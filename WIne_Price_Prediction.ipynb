{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Case: \"Predicting the price of wine with the Keras Functional API and Tensorflow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a wide and deep network using keras (tf.keras) to predict the prices of wines from its description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This Problem is well suited for wide and deep learning.\n",
    "2. It involves text input and there isn't any corellation between a wines' description and it's price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For example:\n",
    "\n",
    "### Input:\n",
    "#### Description: \n",
    "    . powerful vanilla scents rise from the glass, but the fruit, even in this difficult vintage comes out immediately.\n",
    "    . it's tart and sharp, with a strong herbal component, and the wine snaps into focus quickly with fruit, acid, tannin, herb and vanilla in equal proportion.\n",
    "    . Firm and tight, still quite young, this wine needs decanting and/or further age to show its best.\n",
    "    \n",
    "#### Variety: Pinot Noir    \n",
    "\n",
    "\n",
    "### Output:\n",
    "#### Price: $45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install tensorflow\n",
    "!conda install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "layers = keras.layers\n",
    "\n",
    "print(\"You have TensorFlow version\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Source: https://www.kaggle.com/zynicide/wine-reviews/data\n",
    "\n",
    "URL = \"https://storage.googleapis.com/sara-cloud-ml/wine_data.csv\"\n",
    "path = tf.keras.utils.ger_file(URL.split('/')[-1], URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data into pasndas data frame\n",
    "data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data\n",
    "data = data.sample(frac=1)\n",
    "\n",
    "#Print the first 5 rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some preprocessing to limit the # of wine varieties in the dataset\n",
    "data = data[pd.notnull(data['country'])]\n",
    "data = data[pd.notnull(data['price'])]\n",
    "data = data.drop(data.columns, axis=1)\n",
    "\n",
    "variety_threshold = 500 #anuthing less than this will be removed\n",
    "value_counts = data['variety'].value_counts()\n",
    "to_remove = value_counts[value_counts <= variety_threshold].index\n",
    "data.replace(to_remove, np.nan, inplace=True)\n",
    "data = data[pd.notnull(data['variety'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into train and test\n",
    "train_size = int(len(data) * .8)\n",
    "print(\"Train size: %d\" % train_size)\n",
    "print(\"Test size: %d\" % (len(data) - train_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Features\n",
    "description_train = data['description'][:train_size]\n",
    "variety_train = data['variety'][:train_size]\n",
    "\n",
    "#train labels\n",
    "labels_train = data['price'][:train_size]\n",
    "\n",
    "#test features\n",
    "description_test = data['description'][:train_size]\n",
    "variety_test = data['variety'][:train_size]\n",
    "\n",
    "#test labels\n",
    "labels_test = data['price'][:train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tokenizer to preprocess our test descriptions\n",
    "vocab_size = 12000 #hyperparameter experiment\n",
    "tokenize = keras.preprocessing.text.Tokenizer(num_words=vocab_size, char_level=False)\n",
    "tokenize.fit_on_texts(description_train) #only fit the train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wide feature 1: sparse bag of words (bow) vocab_size_vector\n",
    "description_bow_train = tokenize.texts_to_matrix(description_train)\n",
    "description_bow_test = tokenize.texts_to_matrix(description_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wide feature 2: one-hot vector of variety categories\n",
    "\n",
    "# Using sklearn utility to convert label strings to numbered index\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(variety_train)\n",
    "variety_train = encoder.transform(variety_train)\n",
    "variety_test = encoder.transform(variety_test)\n",
    "num_class = np.max(variety_train) + 1\n",
    "\n",
    "# Converting labels to one-hot\n",
    "variety_train = keras.utils.to_categorical(variety_train, num_classes)\n",
    "variety_test = keras.utils.to_categorical(variety_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our wide model with the functional API\n",
    "bow_inputs = layers.Input(shape=(vocab_size))\n",
    "variety_inputs = layers.Input(shape=(num_classes,))\n",
    "merged_layer = layers.concatenate([bow_inputs, variety_inputs])\n",
    "merged_layer = layers.Dense(256, activation='relu')(merged_layer)\n",
    "predictions = layers.Dense(1)(merger_layer)\n",
    "wide_model = keras.Model(inputs=[bow_inputs, variety_inputs], outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "print(wide_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep model feature: word embeddings of wine descriptions\n",
    "\n",
    "train_embed = tokenize.texts_to_sequences(description_train)\n",
    "test_embed = tokenize.texts_to_sequences(description_test)\n",
    "\n",
    "max_seq_length = 170\n",
    "train_embed = keras.preprocessing.sequence.pad_sequences(\n",
    "train_embed, maxlen = max_seq_length, padding=\"post\")\n",
    "test_embed = keras.preprocessing.sequence.pad_sequences(\n",
    "test_embed, maxlen = max_seq_length, padding=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our deep model with functional API\n",
    "\n",
    "deep_inouts = layers.Input(shape=(max_seq_length,))\n",
    "embedding = layers.Embedding(vocab_size, 8, input_length=max_seq_length)(deep_inputs)\n",
    "embedding = layers.Flatten()(embedding)\n",
    "embed_out = keras.Model(inputs=deep_inputs, outputs=embed_out)\n",
    "deep_model = keras.Model(inouts=deep_inputs, outputs=embed_out)\n",
    "print(deep_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the wide and deep into one model\n",
    "merged_out = layers.concatenate([wide_model.output, deep_model.output])\n",
    "merger_out = layers.Dense(1)(merged_out)\n",
    "combined_model = keras.Model(wide_model.input + [deep_model.input], merged_out)\n",
    "print(combined_model.summary())\n",
    "\n",
    "combine_model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training\n",
    "combined_model.fit([description_bow_train, variety_train] + [train_embed], labels_train, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model.evaluate([description_bow_test, variety_test] + [test_embed], labels_test, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating predictions\n",
    "predictions = combined_model.predict([description_bow_test, variety_test] + [test_embed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing predictions with actual values for the first few items in our test dataset\n",
    "num_predictions = 40\n",
    "diff = 0\n",
    "\n",
    "\n",
    "for i in range(num_predictions):\n",
    "    val = predictions[i]\n",
    "    print(description_test.iloc[i])\n",
    "    print('Predicted: ',val[0], 'Actual: ' labels_test.iloc[i], '\\n')\n",
    "    diff += abs(val[0] - labels_test.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the average difference between actual price and the model's predicted price\n",
    "print('Average prediction difference: ', dif / num_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
